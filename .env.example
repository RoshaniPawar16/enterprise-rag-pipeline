# ============================================
# Enterprise RAG Pipeline - Configuration
# ============================================
# Copy this file to .env and fill in your values

# ============================================
# LLM Configuration (choose one)
# ============================================

# Option 1: OpenAI (Recommended - fast responses)
LLM_PROVIDER=openai
LLM_MODEL=gpt-3.5-turbo
OPENAI_API_KEY=sk-your-key-here

# Option 2: Local Ollama (free but slow on CPU)
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2:1b
# Run with: docker compose --profile local-llm up -d

# Option 3: Azure OpenAI (enterprise)
# LLM_PROVIDER=azure_openai
# LLM_MODEL=gpt-4
# AZURE_OPENAI_KEY=your-key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
